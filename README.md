# DHWANI ðŸ”Š

## Description
DHWANI is a Python-based project that aims to assist the hearing impaired by converting sign language into text in real-time. It utilizes computer vision techniques along with machine learning models to recognize and interpret hand gestures.

## Features
- Real-time sign language to text conversion.
- Utilizes computer vision techniques for hand gesture recognition.
- Integration with TensorFlow and MediaPipe for accurate gesture interpretation.
- Supports various sign languages.

## Requirements
To run DHWANI, ensure you have the following dependencies installed:

1. Python
2. OpenCV
3. TensorFlow
4. MediaPipe
5. Numpy

## Installation
1. **Python**: If you haven't already installed Python, download and install it from the [official Python website](https://www.python.org/). Follow the installation instructions for your operating system.

2. **OpenCV**: Install OpenCV by running the following command in your terminal or command prompt:

```
pip install opencv-python

```

3. **TensorFlow**: Install TensorFlow by running the following command:

```
pip install tensorflow

```

4. **MediaPipe**: Install MediaPipe by running the following command:

```
pip install mediapipe

```

5. **Numpy**: Install Numpy by running the following command:

```
pip install numpy
```

## Usage
After installing the required dependencies, you can run DHWANI by executing the main Python script. Ensure your camera is connected and accessible.

```
python dhwani.py

```

## How it works
DHWANI works by capturing video input from a camera, then using computer vision techniques to to detect and track hand gestures in real-time. These gestures are then processed using machine learning models trained with TensorFlow and MediaPipe to interpret the sign language gestures and convert them into text.

## OUTPUT

![Reference Image](/assets/1.png)
